{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a prompt prefix for every task. Prompt prefix consists of instruction and demonstrations.\n",
    "\n",
    "The instruction is obtained from [PromptSource](https://github.com/bigscience-workshop/promptsource) using the notebook `get_instructions.ipynb`, and then manually filtered.\n",
    "\n",
    "The demonstrations are sampled from the `dev` split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See statistics of each tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "CLF_TASKS = [\n",
    "    \"emo\", \"emotion\", \"tweet_eval-emoji\", \"tweet_eval-emotion\", \"tweet_eval-hate\", \"tweet_eval-irony\", \"tweet_eval-offensive\", \n",
    "    \"tweet_eval-sentiment\", \"tweet_eval-stance_abortion\", \"tweet_eval-stance_atheism\", \"tweet_eval-stance_climate\", \n",
    "    \"tweet_eval-stance_feminist\", \"tweet_eval-stance_hillary\", \"climate_fever\", \"health_fact\", \"kilt_fever\", \"liar\", \"tab_fact\", \n",
    "    \"ethos-directed_vs_generalized\", \"ethos-disability\", \"ethos-gender\", \"ethos-national_origin\", \"ethos-race\", \"ethos-religion\", \n",
    "    \"ethos-sexual_orientation\", \"hate_speech_offensive\", \"hate_speech18\", \"hatexplain\", \"anli\", \"glue-mnli\", \"glue-qnli\", \n",
    "    \"glue-rte\", \"glue-wnli\", \"scitail\", \"sick\", \"superglue-cb\", \"superglue-rte\", \"ade_corpus_v2-classification\", \"circa\", \n",
    "    \"discovery\", \"glue-cola\", \"google_wellformed_query\", \"onestop_english\", \"scicite\", \"sms_spam\", \"superglue-wic\", \"superglue-wsc\", \n",
    "    \"trec\", \"trec-finegrained\", \"wiki_auto\", \"wiki_qa\", \"glue-mrpc\", \"glue-qqp\", \"medical_questions_pairs\", \"paws\", \n",
    "    \"amazon_polarity\", \"financial_phrasebank\", \"glue-sst2\", \"imdb\", \"poem_sentiment\", \"rotten_tomatoes\", \"yelp_polarity\", \"ag_news\", \n",
    "    \"dbpedia_14\", \"yahoo_answers_topics\"]  # All 65 classification tasks.\n",
    "QA_TASKS = [\n",
    "    \"boolq\", \"mc_taco\", \"freebase_qa\", \"jeopardy\", \"kilt_hotpotqa\", \"kilt_nq\", \"kilt_trex\", \"kilt_zsre\", \"lama-conceptnet\", \n",
    "    \"lama-google_re\", \"lama-squad\", \"lama-trex\", \"numer_sense\", \"search_qa\", \"squad-no_context\", \"web_questions\", \"eli5-askh\", \n",
    "    \"eli5-asks\", \"eli5-eli5\", \"adversarialqa\", \"biomrc\", \"duorc\", \"hotpot_qa\", \"quoref\", \"ropes\", \"squad-with_context\", \n",
    "    \"superglue-record\", \"tweet_qa\", \"ai2_arc\", \"aqua_rat\", \"codah\", \"commonsense_qa\", \"cosmos_qa\", \"dream\", \"hellaswag\", \"math_qa\", \n",
    "    \"openbookqa\", \"qasc\", \"quail\", \"quarel\", \"quartz-no_knowledge\", \"quartz-with_knowledge\", \"race-high\", \"race-middle\", \"sciq\", \n",
    "    \"social_i_qa\", \"superglue-copa\", \"superglue-multirc\", \"swag\", \"wino_grande\", \"wiqa\"]  # All 51 QA tasks.\n",
    "CG_TASKS = [\n",
    "    \"empathetic_dialogues\", \"kilt_wow\", \"spider\", \"wiki_bio\", \"wiki_split\", \"wikisql\", \"aeslc\", \"gigaword\", \"multi_news\", \n",
    "    \"reddit_tifu-title\", \"reddit_tifu-tldr\", \"samsum\", \"xsum\"]  # All 13 CG tasks.\n",
    "OTHER_TASKS = [\n",
    "    \"acronym_identification\", \"art\", \"common_gen\", \"crawl_domain\", \"crows_pairs\", \"definite_pronoun_resolution\", \"e2e_nlg_cleaned\",\n",
    "    \"limit\", \"piqa\", \"proto_qa\", \"qa_srl\", \"cos_e\", \"blimp-anaphor_gender_agreement\", \"blimp-anaphor_number_agreement\",\n",
    "    \"blimp-determiner_noun_agreement_with_adj_irregular_1\", \"blimp-ellipsis_n_bar_1\", \"blimp-ellipsis_n_bar_2\",\n",
    "    \"blimp-existential_there_quantifiers_1\", \"blimp-irregular_past_participle_adjectives\",\n",
    "    \"blimp-sentential_negation_npi_licensor_present\", \"blimp-sentential_negation_npi_scope\", \"blimp-wh_questions_object_gap\",\n",
    "    \"app_reviews\", \"mocha\", \"yelp_review_full\", \"ade_corpus_v2-dosage\", \"ade_corpus_v2-effect\"\n",
    "]  # 27 other tasks, 4 tasks are omitted (has no instructions)\n",
    "TASK_NAMES = CG_TASKS\n",
    "T5_MODEL = \"t5-base\"\n",
    "MAX_INPUT_LEN = 1024\n",
    "\n",
    "\n",
    "def get_task_prefixes(data_path: str, task_name: str) -> list:\n",
    "    \"\"\"Returns all task prefixes (e.g., adversarialqa_32_13) of a task.\"\"\"\n",
    "    files = sorted(os.listdir(os.path.join(data_path, task_name)))\n",
    "    prefixes = []\n",
    "    for filename in files:\n",
    "        if not filename.endswith(\".tsv\"):\n",
    "            continue\n",
    "        prefix = \"_\".join(filename.split(\"_\")[:-1])\n",
    "        if prefix not in prefixes:\n",
    "            prefixes.append(prefix)\n",
    "    return prefixes\n",
    "\n",
    "def get_all_examples(task_name: str) -> list:\n",
    "    examples = []\n",
    "    count = {}\n",
    "    prefix = get_task_prefixes(\"data/crossfit\", task_name)[0]\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        suffix = \"_\" + split + \".tsv\"\n",
    "        with open(os.path.join(\"data/crossfit\", task_name, prefix + suffix)) as fin:\n",
    "            lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            d = line.strip().split(\"\\t\")\n",
    "            examples.append([d[0], d[1:]])\n",
    "        count[split] = len(lines)\n",
    "    return examples, count\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(T5_MODEL, model_max_length=MAX_INPUT_LEN)\n",
    "\n",
    "data = []\n",
    "for task_name in TASK_NAMES:\n",
    "    examples, count = get_all_examples(task_name)\n",
    "    tokenized_input = tokenizer([ex[0] for ex in examples])\n",
    "    tokenized_target = tokenizer([x for ex in examples for x in ex[1]])\n",
    "    lengths = [len(x) for x in tokenized_input[\"input_ids\"]]\n",
    "    max_target_len = np.max([len(x) for x in tokenized_target[\"input_ids\"]])\n",
    "\n",
    "    data.append([\n",
    "        task_name, len(examples), count[\"train\"], count[\"dev\"], count[\"test\"], max_target_len, np.min(lengths), np.max(lengths),\n",
    "        np.percentile(lengths, 25), np.percentile(lengths, 50), np.percentile(lengths, 75), lengths\n",
    "    ])\n",
    "\n",
    "stats_df = pd.DataFrame(data,\n",
    "                        columns=[\"task_name\", \"n_examples\", \"n_train\", \"n_dev\", \"n_test\", \"max_target_len\",\n",
    "                                 \"min_len\", \"max_len\", \"percentile25\", \"percentile50\", \"percentile75\", \"all_lengths\"])\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(stats_df[[\n",
    "        \"task_name\", \"n_examples\", \"n_train\", \"n_dev\", \"n_test\", \"max_target_len\",\n",
    "        \"min_len\", \"max_len\", \"percentile25\", \"percentile50\", \"percentile75\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks which are removed:\n",
    "* 7 classification tasks:\n",
    "  * `amazon_polarity`, `yahoo_answers_topics`, `yelp_polarity` (too long for k=8)\n",
    "  * `tab_fact`, `onestop_english`, `imdb` (too long even for k=4)\n",
    "  * `tweet_eval-emoji` (T5 cannot recognize emojis)\n",
    "* 6 QA tasks:\n",
    "  * `biomrc`, `duorc`, `quoref`, `quail`, `race-high`, `superglue-multirc` (too long for k=3)\n",
    "* 4 CG tasks:\n",
    "  * `multi_news`, `reddit_tifu-title`, `reddit_tifu-tldr`, `xsum` (too long for k=3)\n",
    "* 4 other tasks:\n",
    "  * `aslg_pc12`, `break-QDMR`, `break-QDMR-high-level`, `kilt_ay2` (no instructions & don't understand the tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df[(stats_df.percentile75 > 120)][[\n",
    "        \"task_name\", \"n_examples\", \"n_train\", \"n_dev\", \"n_test\", \"max_target_len\", \"min_len\", \"max_len\",\n",
    "        \"percentile25\", \"percentile50\", \"percentile75\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(task_name, n_bins=40):\n",
    "    n, bins, patches = plt.hist(stats_df[stats_df.task_name == task_name].iloc[0][\"all_lengths\"], n_bins)\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(\"dbpedia_14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate prompt prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3 for QA tasks, `mocha` and `yelp_review_full`\n",
    "\n",
    "k = 8 for the rest of the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAMES = [\"wiki_bio\"]\n",
    "T5_MODEL = \"t5-base\"\n",
    "MAX_INPUT_LEN = 1024\n",
    "K = 3  # Number of demonstrations.\n",
    "INSTRUCTIONS_FILE = \"data/prompt/instructions_iosep.tsv\"\n",
    "OUTPUT_FILE = \"data/prompt/prompt2.tsv\"\n",
    "\n",
    "\n",
    "# Read instructions data.\n",
    "INSTRUCTIONS_DICT = {}\n",
    "with open(INSTRUCTIONS_FILE) as fin:\n",
    "    lines = fin.readlines()\n",
    "for line in lines:\n",
    "    splits = line.strip().split(\"\\t\")  # Splits into (task_name, instruction, input_output_separator).\n",
    "    INSTRUCTIONS_DICT[splits[0]] = splits[1], splits[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "data = []\n",
    "for task_name in TASK_NAMES:\n",
    "    prefixes = get_task_prefixes(\"data/crossfit\", task_name)\n",
    "    for prefix in prefixes:\n",
    "        # Get dev examples\n",
    "        dev_examples = []\n",
    "        with open(os.path.join(\"data/crossfit\", task_name, prefix + \"_dev.tsv\")) as fin:\n",
    "            lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            d = line.strip().split(\"\\t\")\n",
    "            dev_examples.append([d[0], d[1:]])\n",
    "\n",
    "        # Construct prompt with demos and instructions\n",
    "        demos = random.sample(dev_examples, K)\n",
    "        instructions, iosep = INSTRUCTIONS_DICT[task_name]\n",
    "        demos_text = \" \".join([\"{} {} {}\".format(ex[0], iosep, random.choice(ex[1])) for ex in demos])\n",
    "        prompt = instructions + \" \" + demos_text\n",
    "\n",
    "        data.append([\n",
    "            task_name, prefix, prompt, len(tokenizer(prompt)[\"input_ids\"]), iosep\n",
    "        ])\n",
    "\n",
    "prompt_df = pd.DataFrame(\n",
    "    data, columns=[\"task_name\", \"task_prefix\", \"prompt\", \"prompt_len\", \"io_sep\"])\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(prompt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want at least 75% of the examples have length < 1024.\n",
    "# Let's check the prompts which are too long. We can retry generating prompt for these tasks.\n",
    "def f(row):\n",
    "    max_input_len = stats_df[stats_df.task_name == row.task_name].iloc[0][\"percentile75\"]\n",
    "    return row.prompt_len + max_input_len > MAX_INPUT_LEN\n",
    "\n",
    "prompt_df.loc[prompt_df.apply(f, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results.\n",
    "prompt_df.to_csv(OUTPUT_FILE, index=False, sep=\"\\t\", header=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
