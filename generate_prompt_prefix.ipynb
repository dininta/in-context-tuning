{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "from transformers import T5Tokenizer\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute length stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_examples(task_name: str) -> list:\n",
    "    examples = []\n",
    "    prefix = utils.get_task_prefixes('data', task_name)[0]\n",
    "    for suffix in ['_train.tsv', '_dev.tsv', '_test.tsv']:\n",
    "        with open(os.path.join('data', task_name, prefix + suffix), encoding=\"utf-8\") as fin:\n",
    "            lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            d = unidecode(line).strip().split(\"\\t\")\n",
    "            examples.append([d[0], d[1:]])\n",
    "    return examples\n",
    "\n",
    "def plot_hist(df, task_name, n_bins=40):\n",
    "    n, bins, patches = plt.hist(df[df['task_name'] == task_name].iloc[0]['all_lengths'], n_bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>n_examples</th>\n",
       "      <th>min_len</th>\n",
       "      <th>max_len</th>\n",
       "      <th>percentile25</th>\n",
       "      <th>percentile50</th>\n",
       "      <th>percentile75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>341</td>\n",
       "      <td>22</td>\n",
       "      <td>279</td>\n",
       "      <td>49.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweet_eval-sentiment</td>\n",
       "      <td>2096</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discovery</td>\n",
       "      <td>14268</td>\n",
       "      <td>14</td>\n",
       "      <td>140</td>\n",
       "      <td>42.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glue-rte</td>\n",
       "      <td>341</td>\n",
       "      <td>23</td>\n",
       "      <td>280</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superglue-wsc</td>\n",
       "      <td>168</td>\n",
       "      <td>20</td>\n",
       "      <td>137</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scicite</td>\n",
       "      <td>1014</td>\n",
       "      <td>6</td>\n",
       "      <td>655</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>472</td>\n",
       "      <td>31</td>\n",
       "      <td>109</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>77.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tweet_eval-stance_hillary</td>\n",
       "      <td>165</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tweet_eval-offensive</td>\n",
       "      <td>1388</td>\n",
       "      <td>6</td>\n",
       "      <td>146</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>emotion</td>\n",
       "      <td>2192</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hatexplain</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>glue-cola</td>\n",
       "      <td>1107</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sick</td>\n",
       "      <td>591</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paws</td>\n",
       "      <td>8064</td>\n",
       "      <td>19</td>\n",
       "      <td>142</td>\n",
       "      <td>55.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ethos-sexual_orientation</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>1484</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>40494</td>\n",
       "      <td>14</td>\n",
       "      <td>215</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tweet_eval-emotion</td>\n",
       "      <td>502</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sms_spam</td>\n",
       "      <td>1179</td>\n",
       "      <td>4</td>\n",
       "      <td>235</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>health_fact</td>\n",
       "      <td>1342</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>9911</td>\n",
       "      <td>11</td>\n",
       "      <td>267</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>imdb</td>\n",
       "      <td>25064</td>\n",
       "      <td>11</td>\n",
       "      <td>3607</td>\n",
       "      <td>184.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>423.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ethos-disability</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>1484</td>\n",
       "      <td>16.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>glue-wnli</td>\n",
       "      <td>135</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>scitail</td>\n",
       "      <td>1368</td>\n",
       "      <td>22</td>\n",
       "      <td>109</td>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>trec-finegrained</td>\n",
       "      <td>2168</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>60320</td>\n",
       "      <td>18</td>\n",
       "      <td>3086</td>\n",
       "      <td>63.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>liar</td>\n",
       "      <td>1476</td>\n",
       "      <td>19</td>\n",
       "      <td>102</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>936</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tweet_eval-stance_abortion</td>\n",
       "      <td>162</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>circa</td>\n",
       "      <td>6860</td>\n",
       "      <td>31</td>\n",
       "      <td>69</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tweet_eval-stance_climate</td>\n",
       "      <td>117</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>glue-qnli</td>\n",
       "      <td>5527</td>\n",
       "      <td>17</td>\n",
       "      <td>298</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ethos-directed_vs_generalized</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>1484</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ade_corpus_v2-classification</td>\n",
       "      <td>4768</td>\n",
       "      <td>5</td>\n",
       "      <td>176</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wiki_auto</td>\n",
       "      <td>73345</td>\n",
       "      <td>23</td>\n",
       "      <td>366</td>\n",
       "      <td>52.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hate_speech_offensive</td>\n",
       "      <td>5053</td>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>superglue-wic</td>\n",
       "      <td>702</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>google_wellformed_query</td>\n",
       "      <td>3361</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tweet_eval-irony</td>\n",
       "      <td>1019</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ethos-gender</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>1484</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>onestop_english</td>\n",
       "      <td>210</td>\n",
       "      <td>335</td>\n",
       "      <td>1919</td>\n",
       "      <td>744.5</td>\n",
       "      <td>879.0</td>\n",
       "      <td>1041.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>trec</td>\n",
       "      <td>1283</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rotten_tomatoes</td>\n",
       "      <td>1130</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>kilt_fever</td>\n",
       "      <td>10508</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        task_name  n_examples  min_len  max_len  percentile25  \\\n",
       "0                   superglue-rte         341       22      279          49.0   \n",
       "1            tweet_eval-sentiment        2096        9      100          28.0   \n",
       "2                       discovery       14268       14      140          42.0   \n",
       "3                        glue-rte         341       23      280          50.0   \n",
       "4                   superglue-wsc         168       20      137          32.0   \n",
       "5                         scicite        1014        6      655          56.0   \n",
       "6                       glue-mrpc         472       31      109          55.0   \n",
       "7       tweet_eval-stance_hillary         165       16       64          28.0   \n",
       "8            tweet_eval-offensive        1388        6      146          20.0   \n",
       "9                         emotion        2192        5       90          16.0   \n",
       "10                     hatexplain        2018        6      153          22.0   \n",
       "11                      glue-cola        1107        6       40          10.0   \n",
       "12                           sick         591       15       68          24.0   \n",
       "13                           paws        8064       19      142          55.0   \n",
       "14       ethos-sexual_orientation         151        7     1484          17.0   \n",
       "15                       glue-qqp       40494       14      215          27.0   \n",
       "16             tweet_eval-emotion         502        4       69          20.0   \n",
       "17                       sms_spam        1179        4      235          15.0   \n",
       "18                    health_fact        1342        8       92          16.0   \n",
       "19                      glue-mnli        9911       11      267          31.0   \n",
       "20                           imdb       25064       11     3607         184.0   \n",
       "21               ethos-disability         151        7     1484          16.5   \n",
       "22                      glue-wnli         135       20      120          32.0   \n",
       "23                        scitail        1368       22      109          37.0   \n",
       "24               trec-finegrained        2168        8       48          13.0   \n",
       "25           yahoo_answers_topics       60320       18     3086          63.0   \n",
       "26                           liar        1476       19      102          36.0   \n",
       "27                      glue-sst2         936        4       79          21.0   \n",
       "28     tweet_eval-stance_abortion         162       16       64          29.0   \n",
       "29                          circa        6860       31       69          41.0   \n",
       "30      tweet_eval-stance_climate         117       15       53          30.0   \n",
       "31                      glue-qnli        5527       17      298          43.0   \n",
       "32  ethos-directed_vs_generalized         151        7     1484          17.0   \n",
       "33   ade_corpus_v2-classification        4768        5      176          25.0   \n",
       "34                      wiki_auto       73345       23      366          52.0   \n",
       "35          hate_speech_offensive        5053        5      211          22.0   \n",
       "36                  superglue-wic         702       18       74          26.0   \n",
       "37        google_wellformed_query        3361        8       36          13.0   \n",
       "38               tweet_eval-irony        1019        4       66          17.0   \n",
       "39                   ethos-gender         151        7     1484          17.0   \n",
       "40                onestop_english         210      335     1919         744.5   \n",
       "41                           trec        1283        8       47          13.0   \n",
       "42                rotten_tomatoes        1130        5      100          24.0   \n",
       "43                     kilt_fever       10508        6       71          13.0   \n",
       "\n",
       "    percentile50  percentile75  \n",
       "0           63.0         95.00  \n",
       "1           34.0         40.00  \n",
       "2           53.0         64.00  \n",
       "3           64.0         96.00  \n",
       "4           42.5         67.00  \n",
       "5           73.0         94.00  \n",
       "6           66.5         77.25  \n",
       "7           35.0         41.00  \n",
       "8           33.0         56.00  \n",
       "9           24.0         34.00  \n",
       "10          34.0         52.00  \n",
       "11          12.0         16.00  \n",
       "12          29.0         35.00  \n",
       "13          68.0         80.00  \n",
       "14          25.0         35.00  \n",
       "15          33.0         42.00  \n",
       "16          30.0         38.75  \n",
       "17          24.0         42.00  \n",
       "18          20.0         28.00  \n",
       "19          42.0         57.00  \n",
       "20         258.0        423.00  \n",
       "21          22.0         33.50  \n",
       "22          40.0         50.00  \n",
       "23          46.0         58.00  \n",
       "24          16.0         20.00  \n",
       "25         107.0        186.00  \n",
       "26          42.0         50.00  \n",
       "27          30.0         40.00  \n",
       "28          36.0         42.00  \n",
       "29          45.0         49.00  \n",
       "30          37.0         42.00  \n",
       "31          54.0         68.00  \n",
       "32          24.0         37.50  \n",
       "33          34.0         45.00  \n",
       "34          64.0         79.00  \n",
       "35          34.0         47.00  \n",
       "36          30.0         35.00  \n",
       "37          15.0         17.00  \n",
       "38          25.0         34.00  \n",
       "39          24.0         36.00  \n",
       "40         879.0       1041.00  \n",
       "41          16.0         20.00  \n",
       "42          33.0         43.00  \n",
       "43          15.0         18.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.task_names = utils.get_tasks_list(\n",
    "            'dataloader/custom_tasks_splits/train_classification_test_classification.json', 'train')\n",
    "        self.t5_model = 't5-base'\n",
    "        self.max_input_len = 1024\n",
    "\n",
    "args = TrainingArgs()\n",
    "tokenizer = T5Tokenizer.from_pretrained(args.t5_model, model_max_length=args.max_input_len)\n",
    "\n",
    "data = []\n",
    "for task_name in args.task_names:\n",
    "    examples = get_all_examples(task_name)    \n",
    "    tokenized_input = tokenizer([ex[0] for ex in examples])\n",
    "    lengths = [len(x) for x in tokenized_input['input_ids']]\n",
    "\n",
    "    data.append([\n",
    "        task_name, len(examples), np.min(lengths), np.max(lengths),\n",
    "        np.percentile(lengths, 25), np.percentile(lengths, 50), np.percentile(lengths, 75), lengths\n",
    "    ])\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    data, columns=['task_name', 'n_examples', 'min_len', 'max_len', 'percentile25', 'percentile50', 'percentile75', 'all_lengths'])\n",
    "\n",
    "stats_df[['task_name', 'n_examples', 'min_len', 'max_len', 'percentile25', 'percentile50', 'percentile75']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAARa0lEQVR4nO3da6xdZZ3H8e9vykUjzrRIp2naZlq0yaSamYoNdKIxjmRKKS+KCTHlhTQMsWYsiSZOYtVkYFQSmERNSBBTQ2OZOBYGNTRSp3YYEuMLoAetpYXBHrGENoUeKReNiQ7Of17s5+Ceeu63fU7P95Os7LX/67Kfp2vTX9daz16kqpAkzW9/0usGSJJ6zzCQJBkGkiTDQJKEYSBJAs7rdQMm6pJLLqmVK1f2uhmSNKc88cQTv6yqxWfX52wYrFy5kr6+vl43Q5LmlCTPDVX3MpEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkpjDv0CejJU7Hhpx+fHbr5mhlkjS7OCZgSTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCQxhjBIsiLJI0meSnI0ySda/dYkJ5McatOmrm0+k6Q/yTNJruqqb2y1/iQ7uuqrkjzW6vcluWCqOypJGt5YzgxeBz5VVWuA9cD2JGvasq9U1do27QNoy7YA7wQ2Al9NsiDJAuAu4GpgDXB9137uaPt6B/AycNMU9U+SNAajhkFVnaqqH7f5XwFPA8tG2GQzsKeqfltVvwD6gcvb1F9Vz1bV74A9wOYkAT4IPNC23w1cO8H+SJImYFz3DJKsBN4NPNZKNyc5nGRXkkWttgx4vmuzE602XP1twCtV9fpZ9aE+f1uSviR9AwMD42m6JGkEYw6DJBcB3wY+WVWvAXcDbwfWAqeAL01HA7tV1c6qWldV6xYvXjzdHydJ88aYnlqa5Hw6QfDNqvoOQFW92LX868D32tuTwIquzZe3GsPUXwIWJjmvnR10ry9JmgFjGU0U4B7g6ar6cld9addqHwKOtPm9wJYkFyZZBawGHgcOAqvbyKEL6Nxk3ltVBTwCXNe23wo8OLluSZLGYyxnBu8FPgI8meRQq32WzmigtUABx4GPAVTV0ST3A0/RGYm0vap+D5DkZmA/sADYVVVH2/4+DexJ8kXgJ3TCR5I0Q0YNg6r6EZAhFu0bYZvbgNuGqO8baruqepbOaCNJUg/4C2RJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIkxhEGSFUkeSfJUkqNJPtHqFyc5kORYe13U6klyZ5L+JIeTXNa1r61t/WNJtnbV35PkybbNnUkyHZ2VJA1tLGcGrwOfqqo1wHpge5I1wA7g4apaDTzc3gNcDaxu0zbgbuiEB3ALcAVwOXDLYIC0dT7atd3GyXdNkjRWo4ZBVZ2qqh+3+V8BTwPLgM3A7rbabuDaNr8ZuLc6HgUWJlkKXAUcqKozVfUycADY2Jb9aVU9WlUF3Nu1L0nSDBjXPYMkK4F3A48BS6rqVFv0ArCkzS8Dnu/a7ESrjVQ/MUR9qM/flqQvSd/AwMB4mi5JGsGYwyDJRcC3gU9W1Wvdy9q/6GuK2/ZHqmpnVa2rqnWLFy+e7o+TpHljTGGQ5Hw6QfDNqvpOK7/YLvHQXk+3+klgRdfmy1ttpPryIeqSpBkyltFEAe4Bnq6qL3ct2gsMjgjaCjzYVb+hjSpaD7zaLiftBzYkWdRuHG8A9rdlryVZ3z7rhq59SZJmwHljWOe9wEeAJ5McarXPArcD9ye5CXgO+HBbtg/YBPQDvwFuBKiqM0m+ABxs632+qs60+Y8D3wDeDHy/TZKkGTJqGFTVj4Dhxv1fOcT6BWwfZl+7gF1D1PuAd43WFknS9PAXyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkScB5vW7AbLRyx0PDLjt++zUz2BJJmhmeGUiSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiTGEQZJdSU4nOdJVuzXJySSH2rSpa9lnkvQneSbJVV31ja3Wn2RHV31Vksda/b4kF0xlByVJoxvLmcE3gI1D1L9SVWvbtA8gyRpgC/DOts1XkyxIsgC4C7gaWANc39YFuKPt6x3Ay8BNk+mQJGn8Rg2DqvohcGaM+9sM7Kmq31bVL4B+4PI29VfVs1X1O2APsDlJgA8CD7TtdwPXjq8LkqTJmsw9g5uTHG6XkRa12jLg+a51TrTacPW3Aa9U1etn1YeUZFuSviR9AwMDk2i6JKnbRMPgbuDtwFrgFPClqWrQSKpqZ1Wtq6p1ixcvnomPlKR5YUKPsK6qFwfnk3wd+F57exJY0bXq8lZjmPpLwMIk57Wzg+71JUkzZEJnBkmWdr39EDA40mgvsCXJhUlWAauBx4GDwOo2cugCOjeZ91ZVAY8A17XttwIPTqRNkqSJG/XMIMm3gA8AlyQ5AdwCfCDJWqCA48DHAKrqaJL7gaeA14HtVfX7tp+bgf3AAmBXVR1tH/FpYE+SLwI/Ae6Zqs5JksZm1DCoquuHKA/7F3ZV3QbcNkR9H7BviPqzdEYbSZJ6xF8gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJjCEMkuxKcjrJka7axUkOJDnWXhe1epLcmaQ/yeEkl3Vts7WtfyzJ1q76e5I82ba5M0mmupOSpJGN5czgG8DGs2o7gIerajXwcHsPcDWwuk3bgLuhEx7ALcAVwOXALYMB0tb5aNd2Z3+WJGmajRoGVfVD4MxZ5c3A7ja/G7i2q35vdTwKLEyyFLgKOFBVZ6rqZeAAsLEt+9OqerSqCri3a1+SpBky0XsGS6rqVJt/AVjS5pcBz3etd6LVRqqfGKI+pCTbkvQl6RsYGJhg0yVJZ5v0DeT2L/qagraM5bN2VtW6qlq3ePHimfhISZoXJhoGL7ZLPLTX061+EljRtd7yVhupvnyIuiRpBk00DPYCgyOCtgIPdtVvaKOK1gOvtstJ+4ENSRa1G8cbgP1t2WtJ1rdRRDd07UuSNEPOG22FJN8CPgBckuQEnVFBtwP3J7kJeA74cFt9H7AJ6Ad+A9wIUFVnknwBONjW+3xVDd6U/jidEUtvBr7fJknSDBo1DKrq+mEWXTnEugVsH2Y/u4BdQ9T7gHeN1g5J0vTxF8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSY3iEtf6/lTseGnH58duvmaGWSNLU8cxAkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDHJMEhyPMmTSQ4l6Wu1i5McSHKsvS5q9SS5M0l/ksNJLuvaz9a2/rEkWyfXJUnSeE3FmcHfVtXaqlrX3u8AHq6q1cDD7T3A1cDqNm0D7oZOeAC3AFcAlwO3DAaIJGlmTMdlos3A7ja/G7i2q35vdTwKLEyyFLgKOFBVZ6rqZeAAsHEa2iVJGsZkw6CAHyR5Ism2VltSVafa/AvAkja/DHi+a9sTrTZc/Y8k2ZakL0nfwMDAJJsuSRo02f8H8vuq6mSSPwcOJPnv7oVVVUlqkp/Rvb+dwE6AdevWTdl+JWm+m9SZQVWdbK+nge/Sueb/Yrv8Q3s93VY/Cazo2nx5qw1XlyTNkAmHQZK3JHnr4DywATgC7AUGRwRtBR5s83uBG9qoovXAq+1y0n5gQ5JF7cbxhlaTJM2QyVwmWgJ8N8ngfv6tqv4jyUHg/iQ3Ac8BH27r7wM2Af3Ab4AbAarqTJIvAAfbep+vqjOTaJckaZwmHAZV9Szw10PUXwKuHKJewPZh9rUL2DXRtkiSJsdfIEuSDANJkmEgScIwkCQx+R+d6Swrdzw07LLjt18zgy2RpLHzzECSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSPptoRo303CLw2UWSesczA0mSYSBJMgwkSRgGkiQMA0kShoEkCYeWzioOPZXUK54ZSJIMA0mSYSBJwnsGc8pI9xS8nyBpMjwzkCR5ZnCucCSSpMmYNWcGSTYmeSZJf5IdvW6PJM0ns+LMIMkC4C7g74ATwMEke6vqqd627Nwx2pnDSDyrkM59syIMgMuB/qp6FiDJHmAzYBjMApMJkl4yxKSxmy1hsAx4vuv9CeCKs1dKsg3Y1t7+Oskz4/ycS4BfTqiFs8u50I9p70PumM69v+FcOBZwbvTjXOgDTH8//mKo4mwJgzGpqp3Azolun6SvqtZNYZN64lzox7nQB7Afs8m50AfoXT9myw3kk8CKrvfLW02SNANmSxgcBFYnWZXkAmALsLfHbZKkeWNWXCaqqteT3AzsBxYAu6rq6DR81IQvMc0y50I/zoU+gP2YTc6FPkCP+pGq6sXnSpJmkdlymUiS1EOGgSRp/oTBXHrcRZLjSZ5McihJX6tdnORAkmPtdVGrJ8mdrV+Hk1zWw3bvSnI6yZGu2rjbnWRrW/9Ykq2zoA+3JjnZjsehJJu6ln2m9eGZJFd11Xv6fUuyIskjSZ5KcjTJJ1p9zhyPEfowp45HkjcleTzJT1s//rnVVyV5rLXpvjZ4hiQXtvf9bfnK0fo3JarqnJ/o3JT+OXApcAHwU2BNr9s1QnuPA5ecVfsXYEeb3wHc0eY3Ad8HAqwHHuthu98PXAYcmWi7gYuBZ9vroja/qMd9uBX4xyHWXdO+SxcCq9p3bMFs+L4BS4HL2vxbgZ+19s6Z4zFCH+bU8Wh/phe1+fOBx9qf8f3Allb/GvAPbf7jwNfa/BbgvpH6N1XtnC9nBm887qKqfgcMPu5iLtkM7G7zu4Fru+r3VsejwMIkS3vQPqrqh8CZs8rjbfdVwIGqOlNVLwMHgI3T3vhmmD4MZzOwp6p+W1W/APrpfNd6/n2rqlNV9eM2/yvgaTq/9J8zx2OEPgxnVh6P9mf66/b2/DYV8EHggVY/+1gMHqMHgCuThOH7NyXmSxgM9biLkb5UvVbAD5I8kc4jOACWVNWpNv8CsKTNz/a+jbfds7U/N7fLJ7sGL60wR/rQLjO8m86/SOfk8TirDzDHjkeSBUkOAafpBOrPgVeq6vUh2vRGe9vyV4G3Mc39mC9hMNe8r6ouA64Gtid5f/fC6pwzzrkxwXO13cDdwNuBtcAp4Es9bc04JLkI+Dbwyap6rXvZXDkeQ/Rhzh2Pqvp9Va2l83SFy4G/7G2L/th8CYM59biLqjrZXk8D36Xz5Xlx8PJPez3dVp/tfRtvu2ddf6rqxfYf8/8CX+cPp+azug9Jzqfzl+g3q+o7rTynjsdQfZirxwOgql4BHgH+hs6luMEf/na36Y32tuV/BrzENPdjvoTBnHncRZK3JHnr4DywAThCp72DIzm2Ag+2+b3ADW00yHrg1a7LALPBeNu9H9iQZFE7/d/Qaj1z1j2YD9E5HtDpw5Y2+mMVsBp4nFnwfWvXmO8Bnq6qL3ctmjPHY7g+zLXjkWRxkoVt/s10/r8tT9MJhevaamcfi8FjdB3wX+0sbrj+TY2ZuqPe64nOaImf0blW97let2eEdl5KZ8TAT4Gjg22lc83wYeAY8J/AxfWHkQp3tX49CazrYdu/Ree0/X/oXM+8aSLtBv6ezs2xfuDGWdCHf21tPEznP8ilXet/rvXhGeDq2fJ9A95H5xLQYeBQmzbNpeMxQh/m1PEA/gr4SWvvEeCfWv1SOn+Z9wP/DlzY6m9q7/vb8ktH699UTD6OQpI0by4TSZJGYBhIkgwDSZJhIEnCMJAkYRhIkjAMJEnA/wE/cGSpkLSegwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(stats_df, 'yahoo_answers_topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate prompt prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_dict = {}\n",
    "with open('instruction/instructions_io_sep.tsv') as fin:\n",
    "    lines = fin.readlines()\n",
    "for line in lines:\n",
    "    splits = line.strip().split('\\t')\n",
    "    instructions_dict[splits[0]] = splits[1], splits[2]\n",
    "\n",
    "def get_instructions_and_io_sep(task_name):\n",
    "    return instructions_dict[task_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.task_names = [\"superglue-rte\", \"yahoo_answers_topics\"]\n",
    "        self.data_dir = 'data'\n",
    "        self.t5_model = 't5-base'\n",
    "        self.k = 8\n",
    "        self.max_input_len = 1024\n",
    "\n",
    "args = TrainingArgs()\n",
    "\n",
    "data = []\n",
    "for task_name in args.task_names:\n",
    "    prefixes = utils.get_task_prefixes(args.data_dir, task_name)\n",
    "    for prefix in prefixes:\n",
    "        # Get dev examples\n",
    "        dev_examples = []\n",
    "        with open(os.path.join(args.data_dir, task_name, prefix + \"_dev.tsv\"), encoding=\"utf-8\") as fin:\n",
    "            lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            d = unidecode(line).strip().split(\"\\t\")\n",
    "            dev_examples.append([d[0], d[1:]])\n",
    "        \n",
    "        # Construct prompt with demos and instructions\n",
    "        demos = utils.sample_demos(dev_examples, args.k, None)\n",
    "        instructions, io_sep = get_instructions_and_io_sep(task_name)\n",
    "        prompt = instructions + '\\n' + utils.create_input_text(demos, None, io_sep, '\\n')\n",
    "\n",
    "        data.append([\n",
    "            task_name, prefix, prompt, len(tokenizer(prompt)['input_ids'])\n",
    "        ])\n",
    "\n",
    "prompt_df = pd.DataFrame(\n",
    "    data, columns=['task_name', 'task_prefix', 'prompt', 'prompt_len'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_prefix</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>superglue-rte_16_100</td>\n",
       "      <td>Based on the premise, is the hypothesis true?\\...</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>superglue-rte_16_13</td>\n",
       "      <td>Based on the premise, is the hypothesis true?\\...</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>superglue-rte_16_21</td>\n",
       "      <td>Based on the premise, is the hypothesis true?\\...</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>superglue-rte_16_42</td>\n",
       "      <td>Based on the premise, is the hypothesis true?\\...</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superglue-rte</td>\n",
       "      <td>superglue-rte_16_87</td>\n",
       "      <td>Based on the premise, is the hypothesis true?\\...</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>yahoo_answers_topics_16_100</td>\n",
       "      <td>Classify the document into one of these topics...</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>yahoo_answers_topics_16_13</td>\n",
       "      <td>Classify the document into one of these topics...</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>yahoo_answers_topics_16_21</td>\n",
       "      <td>Classify the document into one of these topics...</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>yahoo_answers_topics_16_42</td>\n",
       "      <td>Classify the document into one of these topics...</td>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yahoo_answers_topics</td>\n",
       "      <td>yahoo_answers_topics_16_87</td>\n",
       "      <td>Classify the document into one of these topics...</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              task_name                  task_prefix  \\\n",
       "0         superglue-rte         superglue-rte_16_100   \n",
       "1         superglue-rte          superglue-rte_16_13   \n",
       "2         superglue-rte          superglue-rte_16_21   \n",
       "3         superglue-rte          superglue-rte_16_42   \n",
       "4         superglue-rte          superglue-rte_16_87   \n",
       "5  yahoo_answers_topics  yahoo_answers_topics_16_100   \n",
       "6  yahoo_answers_topics   yahoo_answers_topics_16_13   \n",
       "7  yahoo_answers_topics   yahoo_answers_topics_16_21   \n",
       "8  yahoo_answers_topics   yahoo_answers_topics_16_42   \n",
       "9  yahoo_answers_topics   yahoo_answers_topics_16_87   \n",
       "\n",
       "                                              prompt  prompt_len  \n",
       "0  Based on the premise, is the hypothesis true?\\...         691  \n",
       "1  Based on the premise, is the hypothesis true?\\...         875  \n",
       "2  Based on the premise, is the hypothesis true?\\...         900  \n",
       "3  Based on the premise, is the hypothesis true?\\...         605  \n",
       "4  Based on the premise, is the hypothesis true?\\...         970  \n",
       "5  Classify the document into one of these topics...        1017  \n",
       "6  Classify the document into one of these topics...        1657  \n",
       "7  Classify the document into one of these topics...        1477  \n",
       "8  Classify the document into one of these topics...        2514  \n",
       "9  Classify the document into one of these topics...        2101  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(prompt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_df.to_csv('instruction/test.tsv', index=False, sep='\\t')\n",
    "# To read: pd.read_csv('instruction/prompt.tsv', sep='\\t', header=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
