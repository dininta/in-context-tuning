{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def compile_stats(data_path):\n",
    "    folders = sorted(os.listdir(data_path))\n",
    "    folders = [x for x in folders if x[0] != \".\"]\n",
    "    data = []\n",
    "    for task_name in folders:\n",
    "        files = sorted(os.listdir(os.path.join(data_path, task_name)))\n",
    "        d = {\"task_name\": task_name}\n",
    "        for filename in files:\n",
    "            if not filename.endswith(\".tsv\"):\n",
    "                continue\n",
    "            col_name = \"_\".join(filename.split(\"_\")[-2:]).replace(\".tsv\", \"\")\n",
    "            with open(os.path.join(data_path, task_name, filename)) as fin:\n",
    "                lines = fin.readlines()\n",
    "            d[col_name] = len(lines)\n",
    "        data.append(d)\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "df = compile_stats(\"data/crossfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>n_train_task</th>\n",
       "      <th>n_val_task</th>\n",
       "      <th>n_test_task</th>\n",
       "      <th>n_train_ex</th>\n",
       "      <th>n_val_ex</th>\n",
       "      <th>n_test_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>104</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>23105</td>\n",
       "      <td>18080</td>\n",
       "      <td>35780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_clf_test_clf</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>25665</td>\n",
       "      <td>2080</td>\n",
       "      <td>13425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_non_nli_test_nli</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28625</td>\n",
       "      <td>0</td>\n",
       "      <td>18758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_non_para_test_para</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29745</td>\n",
       "      <td>0</td>\n",
       "      <td>49448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_non_mrc_qa_test_mrc</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6240</td>\n",
       "      <td>0</td>\n",
       "      <td>33749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_non_mc_qa_test_mc</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>56851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       split  n_train_task  n_val_task  n_test_task  \\\n",
       "0                     random           104          20           15   \n",
       "1         train_clf_test_clf            41           9            8   \n",
       "2     train_non_nli_test_nli            49           0            9   \n",
       "3   train_non_para_test_para            54           0            4   \n",
       "4  train_non_mrc_qa_test_mrc            39           0            6   \n",
       "5    train_non_mc_qa_test_mc            25           0           20   \n",
       "\n",
       "   n_train_ex  n_val_ex  n_test_ex  \n",
       "0       23105     18080      35780  \n",
       "1       25665      2080      13425  \n",
       "2       28625         0      18758  \n",
       "3       29745         0      49448  \n",
       "4        6240         0      33749  \n",
       "5        4000         0      56851  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_num_test_examples(task_names):\n",
    "    return df[df.task_name.isin(task_names)][\"100_test\"].sum()\n",
    "\n",
    "def get_num_train_examples(task_names, include_test=False):\n",
    "    def f1(row):\n",
    "        return row[\"100_train\"] + row[\"13_train\"] + row[\"21_train\"] + row[\"42_train\"] + row[\"87_train\"]\n",
    "    def f2(row):\n",
    "        return row[\"100_train\"] + row[\"13_train\"] + row[\"21_train\"] + row[\"42_train\"] + row[\"87_train\"] + row[\"100_test\"]\n",
    "    if include_test:\n",
    "        return df[df.task_name.isin(task_names)].apply(f2, axis=1).sum()\n",
    "    return df[df.task_name.isin(task_names)].apply(f1, axis=1).sum()\n",
    "\n",
    "TASKS_SPLITS = [\n",
    "    (\"data/custom_tasks_splits/random.json\", False),\n",
    "    (\"data/custom_tasks_splits/train_clf_test_clf.json\", False),\n",
    "    (\"data/custom_tasks_splits/train_non_nli_test_nli.json\", False),\n",
    "    (\"data/custom_tasks_splits/train_non_para_test_para.json\", False),\n",
    "    (\"data/custom_tasks_splits/train_non_mrc_qa_test_mrc.json\", False),\n",
    "    (\"data/custom_tasks_splits/train_non_mc_qa_test_mc.json\", False),\n",
    "]\n",
    "\n",
    "data = []\n",
    "for task_split, include_test in TASKS_SPLITS:\n",
    "    with open(task_split, \"r\") as fin:\n",
    "        split_dict = json.load(fin)\n",
    "    \n",
    "    has_dev = len(split_dict[\"dev\"]) > 0\n",
    "\n",
    "    n_train_task = len(split_dict[\"train\"])\n",
    "    n_val_task = 0 if not has_dev else len(split_dict[\"dev\"])\n",
    "    n_test_task = len(split_dict[\"test\"])\n",
    "\n",
    "    n_train_ex = get_num_train_examples(split_dict[\"train\"], include_test)\n",
    "    n_val_ex = 0 if not has_dev else get_num_train_examples(split_dict[\"dev\"])\n",
    "    n_test_ex = get_num_test_examples(split_dict[\"test\"])\n",
    "\n",
    "    data.append([\n",
    "        task_split.split(\"/\")[-1].replace(\".json\", \"\"),\n",
    "        n_train_task, n_val_task, n_test_task,\n",
    "        n_train_ex, n_val_ex, n_test_ex])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"split\", \"n_train_task\", \"n_val_task\", \"n_test_task\",\n",
    "    \"n_train_ex\", \"n_val_ex\", \"n_test_ex\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
