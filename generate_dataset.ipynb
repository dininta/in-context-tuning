{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import T5Tokenizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "TASKS_SPLITS = \"data/custom_tasks_splits/train_non_mc_qa_test_mc.json\"\n",
    "OUTPUT_FILE = {\n",
    "    \"train\": \"data/train-train_non_mc_qa_test_mc.tsv\",\n",
    "    #\"dev\": \"data/dev-train_non_mc_qa_test_mc.tsv\",\n",
    "    \"test\": \"data/test-train_non_mc_qa_test_mc.tsv\"\n",
    "}\n",
    "COUNT_OUTPUT_FILE = \"data/counts-train_non_mc_qa_test_mc.json\"\n",
    "DATA_PATH = \"data/crossfit\"\n",
    "MIN_EXAMPLES_PER_PREFIX = 32\n",
    "INPUT_MAX_LEN = 1024\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "def read_prompt_dict(filename: str) -> dict:\n",
    "    result = {}\n",
    "    df = pd.read_csv(filename, header=None, sep=\"\\t\", names=[\"task_name\", \"task_prefix\", \"prompt\", \"prompt_len\", \"io_sep\"])\n",
    "    for _, row in df.iterrows():\n",
    "        result[row.task_prefix] = row.prompt_len\n",
    "    return result\n",
    "\n",
    "PROMPT_DICT = read_prompt_dict(\"data/prompt/prompt.tsv\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_length=INPUT_MAX_LEN)\n",
    "\n",
    "def get_task_prefixes(data_path: str, task_name: str) -> list:\n",
    "    \"\"\"Returns all task prefixes (e.g., adversarialqa_32_13) of a task.\"\"\"\n",
    "    files = sorted(os.listdir(os.path.join(data_path, task_name)))\n",
    "    prefixes = []\n",
    "    for filename in files:\n",
    "        if not filename.endswith(\".tsv\"):\n",
    "            continue\n",
    "        prefix = \"_\".join(filename.split(\"_\")[:-1])\n",
    "        if prefix not in prefixes:\n",
    "            prefixes.append(prefix)\n",
    "    return prefixes\n",
    "\n",
    "def get_tasks_list(filename, split_name):\n",
    "    with open(filename, \"r\") as fin:\n",
    "        split_dict = json.load(fin)\n",
    "    return split_dict[split_name]\n",
    "\n",
    "def get_n_tokens(text: str) -> int:\n",
    "    return len(tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "def is_input_valid(task_prefix: str, input_text: str) -> bool:\n",
    "    max_allowed = INPUT_MAX_LEN - PROMPT_DICT[task_prefix]\n",
    "    n_tokens = get_n_tokens(input_text)\n",
    "    return n_tokens <= max_allowed\n",
    "\n",
    "\n",
    "stats = []\n",
    "all_targets_len = []\n",
    "for split in OUTPUT_FILE.keys():\n",
    "    print(\"Generating data for split: {}\".format(split))\n",
    "    task_names = get_tasks_list(TASKS_SPLITS, split)\n",
    "    data = []\n",
    "    for task_name in tqdm(task_names):\n",
    "        for prefix in get_task_prefixes(DATA_PATH, task_name):\n",
    "            filename = prefix + \"_test.tsv\" if split == \"test\" else prefix + \"_train.tsv\"\n",
    "            with open(os.path.join(DATA_PATH, task_name, filename)) as fin:\n",
    "                lines = fin.readlines()\n",
    "            targets_len = []\n",
    "            for line in lines:\n",
    "                d = unidecode(line).strip().split(\"\\t\")\n",
    "                if is_input_valid(prefix, d[0]):\n",
    "                    target = random.choice(d[1:])\n",
    "                    data.append([task_name, prefix, d[0], target] + d[1:])\n",
    "                    targets_len.append(get_n_tokens(target))\n",
    "\n",
    "            # If the number of examples per task prefix is less than the threshold, sample from test set.\n",
    "            n_retry = 10\n",
    "            while len(targets_len) < MIN_EXAMPLES_PER_PREFIX and n_retry > 0:\n",
    "                n_retry -= 1\n",
    "                with open(os.path.join(DATA_PATH, task_name, prefix + \"_test.tsv\")) as fin:\n",
    "                    lines = fin.readlines()\n",
    "                lines = random.sample(lines, MIN_EXAMPLES_PER_PREFIX - len(targets_len))\n",
    "                for line in lines:\n",
    "                    d = unidecode(line).strip().split(\"\\t\")\n",
    "                    if is_input_valid(prefix, d[0]):\n",
    "                        target = random.choice(d[1:])\n",
    "                        data.append([task_name, prefix, d[0], target] + d[1:])\n",
    "                        targets_len.append(get_n_tokens(target))\n",
    "\n",
    "            stats.append([split, task_name, prefix, len(targets_len), np.max(targets_len) if targets_len else 0])\n",
    "            all_targets_len.extend(targets_len)\n",
    "\n",
    "    # Save every split into a TSV file.\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(OUTPUT_FILE[split], index=False, sep=\"\\t\", header=None)\n",
    "\n",
    "stats_df = pd.DataFrame(stats, columns=[\"split\", \"task_name\", \"task_prefix\", \"n_examples\", \"max_target_len\"])\n",
    "\n",
    "# Save number of examples.\n",
    "count_df = stats_df[[\"split\", \"n_examples\"]].groupby([\"split\"]).sum().reset_index()\n",
    "count_df.loc[count_df.split == \"dev\", \"split\"] = \"validation\"\n",
    "json.dump(dict(zip(count_df.split, count_df.n_examples)), open(COUNT_OUTPUT_FILE, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None): \n",
    "    display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max target len: {}\".format(np.max(all_targets_len)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n, bins, patches = plt.hist([x for x in all_targets_len if x > 32], 40)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
