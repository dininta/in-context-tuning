{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import t5\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "TASKS_SPLITS = \"data/custom_tasks_splits/train_non_mc_qa_test_mc.json\"\n",
    "OUTPUT_FILE = {\n",
    "    \"train\": \"data/v2/train-train_non_mc_qa_test_mc.tsv\",\n",
    "    \"test\": \"data/v2/test-train_non_mc_qa_test_mc.tsv\"\n",
    "}\n",
    "COUNT_OUTPUT_FILE = \"data/v2/counts-train_non_mc_qa_test_mc.json\"\n",
    "DATA_PATH = \"data/crossfit\"\n",
    "INPUT_MAX_LEN = 1018\n",
    "vocab = t5.data.get_default_vocabulary()\n",
    "random.seed(0)\n",
    "\n",
    "def get_n_tokens(text: str) -> int:\n",
    "    return vocab.encode_tf(tf.constant(text)).shape[0]\n",
    "\n",
    "def read_prompt_dict(filename: str) -> dict:\n",
    "    result = {}\n",
    "    df = pd.read_csv(filename, header=None, sep=\"\\t\", names=[\"task_name\", \"task_prefix\", \"prompt\", \"prompt_len\", \"io_sep\"])\n",
    "    for _, row in df.iterrows():\n",
    "        result[row.task_prefix] = get_n_tokens(row.prompt)\n",
    "    return result\n",
    "\n",
    "def get_task_prefixes(data_path: str, task_name: str) -> list:\n",
    "    \"\"\"Returns all task prefixes (e.g., adversarialqa_32_13) of a task.\"\"\"\n",
    "    files = sorted(os.listdir(os.path.join(data_path, task_name)))\n",
    "    prefixes = []\n",
    "    for filename in files:\n",
    "        if not filename.endswith(\".tsv\"):\n",
    "            continue\n",
    "        prefix = \"_\".join(filename.split(\"_\")[:-1])\n",
    "        if prefix not in prefixes:\n",
    "            prefixes.append(prefix)\n",
    "    return prefixes\n",
    "\n",
    "def get_tasks_list(filename, split_name):\n",
    "    with open(filename, \"r\") as fin:\n",
    "        split_dict = json.load(fin)\n",
    "    return split_dict[split_name]\n",
    "\n",
    "def is_input_valid(task_prefix: str, input_text: str) -> bool:\n",
    "    max_allowed = INPUT_MAX_LEN - PROMPT_DICT[task_prefix]\n",
    "    n_tokens = get_n_tokens(input_text)\n",
    "    return n_tokens <= max_allowed\n",
    "\n",
    "PROMPT_DICT = read_prompt_dict(\"data/prompt/prompt.tsv\")\n",
    "stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = get_tasks_list(TASKS_SPLITS, \"test\")\n",
    "data = []\n",
    "for task_name in tqdm(task_names):\n",
    "    for prefix in get_task_prefixes(DATA_PATH, task_name):\n",
    "        with open(os.path.join(DATA_PATH, task_name, prefix + \"_test.tsv\")) as fin:\n",
    "            lines = fin.readlines()\n",
    "        targets_len = []\n",
    "        for line in lines:\n",
    "            d = unidecode(line).strip().split(\"\\t\")\n",
    "            if is_input_valid(prefix, d[0]):\n",
    "                target = random.choice(d[1:])\n",
    "                data.append([task_name, prefix, d[0], target] + d[1:])\n",
    "                targets_len.append(get_n_tokens(target))\n",
    "        stats.append([\"test\", task_name, prefix, len(targets_len), np.max(targets_len) if targets_len else 0])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(OUTPUT_FILE[\"test\"], index=False, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = get_tasks_list(TASKS_SPLITS, \"train\")\n",
    "data = []\n",
    "for task_name in tqdm(task_names):\n",
    "    prefixes = get_task_prefixes(DATA_PATH, task_name)\n",
    "    prefixes_dict = {j:i for i, j in enumerate(prefixes)}\n",
    "    with open(os.path.join(DATA_PATH, task_name, prefixes[0] + \"_test.tsv\")) as fin:\n",
    "        test_lines = fin.readlines()\n",
    "    test_prefixes = np.array(random.choices(range(len(prefixes)), k=len(test_lines)))\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        with open(os.path.join(DATA_PATH, task_name, prefix + \"_train.tsv\")) as fin:\n",
    "            lines = fin.readlines()\n",
    "        targets_len = []\n",
    "        for line in lines:\n",
    "            d = unidecode(line).strip().split(\"\\t\")\n",
    "            if is_input_valid(prefix, d[0]):\n",
    "                target = random.choice(d[1:])\n",
    "                data.append([task_name, prefix, d[0], target] + d[1:])\n",
    "                targets_len.append(get_n_tokens(target))\n",
    "        \n",
    "        # Add examples from test set into `data`\n",
    "        test_prefix_indices = np.where(test_prefixes == prefixes_dict[prefix])[0]\n",
    "        for idx in test_prefix_indices:\n",
    "            d = unidecode(test_lines[idx]).strip().split(\"\\t\")\n",
    "            if is_input_valid(prefix, d[0]):\n",
    "                target = random.choice(d[1:])\n",
    "                data.append([task_name, prefix, d[0], target] + d[1:])\n",
    "                targets_len.append(get_n_tokens(target))\n",
    "\n",
    "        stats.append([\"train\", task_name, prefix, len(targets_len), np.max(targets_len) if targets_len else 0])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(OUTPUT_FILE[\"train\"], index=False, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(stats, columns=[\"split\", \"task_name\", \"task_prefix\", \"n_examples\", \"max_target_len\"])\n",
    "\n",
    "# Save number of examples.\n",
    "count_df = stats_df[[\"split\", \"n_examples\"]].groupby([\"split\"]).sum().reset_index()\n",
    "json.dump(dict(zip(count_df.split, count_df.n_examples)), open(COUNT_OUTPUT_FILE, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None): \n",
    "    display(stats_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
