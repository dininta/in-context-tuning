{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import metrics\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.optimization import Adafactor\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.task_name = 'paws'\n",
    "        self.task_prefix = 'paws_16_100'\n",
    "        self.test_filename = 'paws_16_100_test.tsv'\n",
    "        self.data_dir = 'data/crossfit'\n",
    "        self.output_dir = 'output'\n",
    "        self.finetuned_model_name = \"paws_16_100_base_{}.pt\"\n",
    "        self.t5_model = 'google/t5-v1_1-base'\n",
    "        self.batch_size = 8\n",
    "        self.max_input_len = 1024\n",
    "        self.max_target_len = 8\n",
    "        self.n_epochs = 1\n",
    "        self.total_steps = 1000\n",
    "        self.eval_period = 1  # Evaluate with validation step every 100 steps\n",
    "        self.save_period = 200  # Save model every 200 steps\n",
    "\n",
    "args = TrainingArgs()\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, args, tokenizer, split):\n",
    "        self.split = split\n",
    "        self.all_targets = []  # Only for test set. Empty otherwise.\n",
    "        examples = []\n",
    "        filename = args.task_prefix + \"_\" + split + \".tsv\" if split != \"test\" else args.test_filename\n",
    "\n",
    "        with open(os.path.join(args.data_dir, args.task_name, filename), encoding=\"utf-8\") as fin:\n",
    "            lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            d = unidecode(line).strip().split(\"\\t\")\n",
    "            examples.append([d[0], random.choice(d[1:])])\n",
    "            if self.split == \"test\":\n",
    "                self.all_targets.append(d[1:])\n",
    "\n",
    "        tokenized_input = tokenizer([ex[0] for ex in examples], padding=True,\n",
    "                                    truncation=True, max_length=args.max_input_len)\n",
    "        self.input_ids = tokenized_input['input_ids']\n",
    "        self.attention_mask = tokenized_input['attention_mask']\n",
    "\n",
    "        if self.split != \"test\":\n",
    "            tokenized_output = tokenizer([ex[1] for ex in examples], padding=True,\n",
    "                                         truncation=True, max_length=args.max_target_len)\n",
    "            # Replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "            label_ids = tokenized_output['input_ids']\n",
    "            for i in range(len(label_ids)):\n",
    "                label_ids[i] = [-100 if id == tokenizer.pad_token_id else id for id in label_ids[i]]\n",
    "            self.label_ids = label_ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"test\":\n",
    "            return (torch.LongTensor(self.input_ids[idx]),\n",
    "                    torch.LongTensor(self.attention_mask[idx]))\n",
    "        else:\n",
    "            return (torch.LongTensor(self.input_ids[idx]),\n",
    "                    torch.LongTensor(self.attention_mask[idx]),\n",
    "                    torch.LongTensor(self.label_ids[idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.INFO)\n",
    "\n",
    "logFileFormatter = logging.Formatter(\n",
    "    fmt='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    ")\n",
    "fileHandler = logging.FileHandler(filename=os.path.join(args.output_dir, 'log.txt'))\n",
    "fileHandler.setFormatter(logFileFormatter)\n",
    "fileHandler.setLevel(level=logging.INFO)\n",
    "\n",
    "logger.addHandler(fileHandler)\n",
    "\n",
    "def random_seed(value):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    np.random.seed(value)\n",
    "    random.seed(value)\n",
    "\n",
    "random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(args.t5_model, model_max_length=1024)\n",
    "\n",
    "# Read training set\n",
    "train_dataset = MyDataset(args, tokenizer, \"train\")\n",
    "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=args.batch_size)\n",
    "\n",
    "# Read validation set\n",
    "val_dataset = MyDataset(args, tokenizer, \"dev\")\n",
    "val_loader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(args.t5_model).to(device)\n",
    "\n",
    "optimizer = Adafactor(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []  # Train loss every eval_period step\n",
    "val_losses = []  # Val loss every eval_period step\n",
    "train_loss = []\n",
    "step = 0\n",
    "best_loss = float(\"inf\")\n",
    "step_of_best_loss = 0\n",
    "stop_training = False\n",
    "model.train()\n",
    "\n",
    "for epoch in range(args.n_epochs):    \n",
    "    for batch in tqdm(train_loader, desc=\"Epoch {}\".format(epoch)):\n",
    "        input_ids, attention_mask, label_id = batch\n",
    "        loss = model(\n",
    "            input_ids=input_ids.to(device),\n",
    "            attention_mask=attention_mask.to(device),\n",
    "            labels=label_id.to(device)).loss\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "\n",
    "        # Evaluate with validation set\n",
    "        if step % args.eval_period == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, label_id = batch\n",
    "                loss = model(\n",
    "                    input_ids=input_ids.to(device),\n",
    "                    attention_mask=attention_mask.to(device),\n",
    "                    labels=label_id.to(device)).loss\n",
    "                val_loss += loss.detach().item()\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            train_losses.append(np.mean(train_loss))\n",
    "            logger.info('Step: {}; Train loss: {}; Val loss: {}'.format(step, np.mean(train_loss), val_loss))\n",
    "            train_loss = []\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                step_of_best_loss = step\n",
    "                logger.info('Found model with best loss at step {}'.format(step))\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(args.output_dir, args.finetuned_model_name.format(step)))\n",
    "            model.train()\n",
    "\n",
    "        if step % args.save_period == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(args.output_dir, args.finetuned_model_name.format(step)))\n",
    "\n",
    "        if step >= args.total_steps:\n",
    "            stop_training = True\n",
    "            break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()        \n",
    "    if stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(zip(range(args.eval_period, step + 1, args.eval_period), train_losses))\n",
    "plt.plot(*zip(*li), label=\"train\")\n",
    "li = list(zip(range(args.eval_period, step + 1, args.eval_period), val_losses))\n",
    "plt.plot(*zip(*li), label=\"val\")\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test set\n",
    "test_dataset = MyDataset(args, tokenizer, \"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "\n",
    "# Use the best model\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(args.output_dir, args.finetuned_model_name.format(step_of_best_loss)),\n",
    "    map_location=device))\n",
    "\n",
    "predictions = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids, attention_mask = batch\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        attention_mask=attention_mask.to(device),\n",
    "        max_length=args.max_target_len,\n",
    "        early_stopping=True)\n",
    "    predictions.extend(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "test_performance = metrics.evaluate(\n",
    "    predictions, test_dataset.all_targets, metrics.METRICS[args.task_name])\n",
    "logger.info(\"Task: {}; Test score: {}; Metric: {}\".format(\n",
    "    args.task_prefix, test_performance, metrics.METRICS[args.task_name]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
