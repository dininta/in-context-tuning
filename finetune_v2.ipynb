{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import utils\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICTDevDataset(Dataset):\n",
    "\n",
    "    def __init__(self, raw_data, tokenizer, args):\n",
    "        prompt_prefix_dict = utils.read_prompt_prefix_dict(args.prompt_data)\n",
    "        instructions_dict = utils.read_instruction_dict(args.instruction_data)\n",
    "\n",
    "        self.examples = []\n",
    "        for task in raw_data:\n",
    "            for train_example in task['train_examples']:\n",
    "                _, io_sep = instructions_dict[task['task_name']]\n",
    "                input_text = '{}\\n{} {}'.format(\n",
    "                    prompt_prefix_dict[task['task_prefix']],\n",
    "                    train_example[0],\n",
    "                    io_sep)\n",
    "                target = random.choice(train_example[1])\n",
    "                if len(tokenizer(input_text)['input_ids']) <= args.max_input_len:\n",
    "                    self.examples.append([input_text, target])\n",
    "\n",
    "        tokenized_input = tokenizer([example[0] for example in self.examples], padding=True, truncation=True, max_length=args.max_input_len)\n",
    "        tokenized_output = tokenizer([example[1] for example in self.examples], padding=True, truncation=True, max_length=args.max_target_len)\n",
    "\n",
    "        # Replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "        label_ids = tokenized_output['input_ids']\n",
    "        for i in range(len(label_ids)):\n",
    "            label_ids[i] = [-100 if id == tokenizer.pad_token_id else id for id in label_ids[i]]\n",
    "\n",
    "        self.input_ids = tokenized_input['input_ids']  # list of list\n",
    "        self.attention_mask = tokenized_input['attention_mask']\n",
    "        self.label_ids = label_ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.input_ids[idx]), torch.LongTensor(self.attention_mask[idx]), torch.LongTensor(self.label_ids[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.train_data = 'data/train-train_classification_test_classification.json'\n",
    "        self.prompt_data = 'instruction/prompt.tsv'\n",
    "        self.instruction_data = 'instruction/instructions_io_sep.tsv'\n",
    "        self.data_dir = 'data'\n",
    "        self.output_dir = 'output'\n",
    "        self.checkpoint_path = None\n",
    "        self.finetuned_model_name = 'mini_classification_{}.pt'\n",
    "        self.t5_model = 't5-base'\n",
    "        self.learning_rate = 1e-5\n",
    "        self.batch_size = 8\n",
    "        self.k = 8\n",
    "        self.max_input_len = 1024\n",
    "        self.max_target_len = 32\n",
    "        self.st_epoch = 0\n",
    "        self.n_epochs = 1\n",
    "\n",
    "args = TrainingArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Initialize variables, read data, load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.INFO)\n",
    "\n",
    "logFileFormatter = logging.Formatter(\n",
    "    fmt='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    ")\n",
    "fileHandler = logging.FileHandler(filename=os.path.join(args.output_dir, 'log.txt'))\n",
    "fileHandler.setFormatter(logFileFormatter)\n",
    "fileHandler.setLevel(level=logging.INFO)\n",
    "\n",
    "logger.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(args.t5_model, model_max_length=1024)\n",
    "\n",
    "# Read training set\n",
    "train_raw_data = json.load(open(args.train_data))\n",
    "train_dataset = ICTDevDataset(train_raw_data, tokenizer, args)\n",
    "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(args.t5_model).to(device)\n",
    "if args.checkpoint_path is not None:\n",
    "    model.load_state_dict(torch.load(args.checkpoint_path, map_location=device))\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "step = 0\n",
    "\n",
    "for epoch in range(args.st_epoch, args.st_epoch + args.n_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in tqdm(train_loader, desc=\"Epoch {}\".format(epoch)):\n",
    "        input_ids, attention_mask, label_id = batch\n",
    "        loss = model(\n",
    "            input_ids=input_ids.to(device),\n",
    "            attention_mask=attention_mask.to(device),\n",
    "            labels=label_id.to(device)).loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "\n",
    "    train_losses.append(np.mean(losses))\n",
    "    logger.info('Epoch {}; Train loss: {}'.format(epoch, np.mean(losses)))\n",
    "    logger.info('Loss per step: {}'.format(losses))\n",
    "\n",
    "    # Always save checkpoint in every epoch\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(args.output_dir, args.finetuned_model_name.format(epoch))\n",
    "    )\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
